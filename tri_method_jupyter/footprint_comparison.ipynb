{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'footprint.footprint_funcs' from '/Users/miksch/git/triangle-method/tri_method_jupyter/footprint/footprint_funcs.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import footprint.footprint_funcs as ff\n",
    "import footprint.calc_footprint_FFP_climatology as myfootprint_s\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pyproj as proj\n",
    "import cartopy.crs as ccrs\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "importlib.reload(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_dir = '/Users/miksch/Thesis_Files/Processed/Eagle_Lake/'\n",
    "tri_dir = '/Users/miksch/Thesis_Files/Processed/tri_method/'\n",
    "\n",
    "#Read in flux footprint data\n",
    "\n",
    "#Read in sigv data\n",
    "\n",
    "def date_parse_sigv_17(doy,hr):\n",
    "    '''\n",
    "    Sigv date parser (pd.read_csv) for sigv files\n",
    "    Change yr to year being processed \n",
    "    '''\n",
    "    \n",
    "    yr='2017'\n",
    "    \n",
    "    if '2400' in hr:\n",
    "        hr = '000'\n",
    "        return pd.datetime.strptime(f'{yr}{int(doy)+1}{int(hr):04}', '%Y%j%H%M')\n",
    "    else:\n",
    "        return pd.datetime.strptime(f'{yr}{doy}{int(hr):04}', '%Y%j%H%M')\n",
    "    \n",
    "def date_parse_sigv_18(doy,hr):\n",
    "    '''\n",
    "    Sigv date parser (pd.read_csv) for sigv files\n",
    "    Change yr to year being processed \n",
    "    '''\n",
    "    \n",
    "    yr='2018'\n",
    "    \n",
    "    if '2400' in hr:\n",
    "        hr = '000'\n",
    "        return pd.datetime.strptime(f'{yr}{int(doy)+1}{int(hr):04}', '%Y%j%H%M')\n",
    "    else:\n",
    "        return pd.datetime.strptime(f'{yr}{doy}{int(hr):04}', '%Y%j%H%M')\n",
    "\n",
    "sigv_17_file = os.path.join(flux_dir,'EL_17','cross_var','el17_crosswind.csv')\n",
    "sigv_17 = pd.read_csv(sigv_17_file,delim_whitespace=True,parse_dates={'TIMESTAMP':[0,1]}, \n",
    "                      date_parser=date_parse_sigv_17, index_col=0, names=['DOY','hrmin','mag_v','sig_v'])\n",
    "\n",
    "sigv_18_file = os.path.join(flux_dir,'EL_18','cross_var','el18_crosswind.csv')\n",
    "sigv_18 = pd.read_csv(sigv_17_file,delim_whitespace=True,parse_dates={'TIMESTAMP':[0,1]}, \n",
    "                      date_parser=date_parse_sigv_18, index_col=0,  names=['DOY','hrmin','mag_v','sig_v'])\n",
    "\n",
    "sigv = pd.concat([sigv_17, sigv_18])\n",
    "\n",
    "#Read in flux data\n",
    "flux = pd.read_csv(os.path.join(flux_dir,'closed_eb.csv'), index_col=[0], parse_dates=True)\n",
    "\n",
    "data = pd.concat([flux,sigv],axis=1,sort=True)\n",
    "\n",
    "#Get all landsat dates + times\n",
    "overpass_dates = ['2017-06-04', '2017-06-20', '2017-10-10',\n",
    "                  '2018-06-07', '2018-06-23', '2018-07-09', '2018-08-10', '2018-09-11', '2018-09-27', '2018-10-13' \n",
    "                 ]\n",
    "\n",
    "overpass_times = [f'{day}T11:07' for day in overpass_dates]\n",
    "\n",
    "#Interpolate data to overpass times, then change datetimeindex to dates\n",
    "min_data = data.resample('T',label='right').interpolate()\n",
    "min_data = min_data[min_data.index.isin(overpass_times)]\n",
    "min_data.index = min_data.index - pd.Timedelta(hours=11,minutes=7)\n",
    "min_data['ef_footprint_raw'] = None\n",
    "min_data['ef_footprint'] = None\n",
    "\n",
    "#Read in triangle method output\n",
    "raster_str = 'ls8_sharp'\n",
    "raster = xr.open_dataset(os.path.join(tri_dir,raster_str,f'{raster_str}_v03_test.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2017-06-04 00:00:00\n",
      "0.6982490051659183\n",
      "Date: 2017-06-20 00:00:00\n",
      "0.7514454176695972\n",
      "Date: 2017-10-10 00:00:00\n",
      "0.7897253772370776\n",
      "Date: 2018-06-07 00:00:00\n",
      "0.7514045563357499\n",
      "Date: 2018-06-23 00:00:00\n",
      "0.7234870105255029\n",
      "Date: 2018-07-09 00:00:00\n",
      "0.81245583705452\n",
      "Date: 2018-08-10 00:00:00\n",
      "0.7279482744897575\n",
      "Date: 2018-09-11 00:00:00\n",
      "0.8201613409617845\n",
      "Date: 2018-09-27 00:00:00\n",
      "0.8054021186385109\n",
      "Date: 2018-10-13 00:00:00\n",
      "0.7919141313299405\n"
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "zm_s = 2.78 #Measurement height [m]\n",
    "h_c = 0.05 #Height of canopy [m]\n",
    "d = (2./3.) * h_c\n",
    "h_s = 2000. #Height of boundary layer [m]\n",
    "min_data['ol'] = zm_s/min_data['z_L'] #Monin-Obukhov length [m]\n",
    "dx = 3. #Model resolution [m]\n",
    "origin_d = 600. #Model bounds distance from origin [m]\n",
    "start_hr = 7\n",
    "end_hr = 20\n",
    "hours = np.arange(start_hr,end_hr+1) #np.ndarray of hours\n",
    "\n",
    "#Convert local lat/lon to local UTM (Eagle Lake: UTM 12)\n",
    "station_coord = (-112.050747,41.166695) #Eagle Lake lat/lon in WGS-84\n",
    "in_proj = proj.Proj(init='EPSG:4326')\n",
    "out_proj = proj.Proj(init='EPSG:32612')\n",
    "(station_x,station_y) = proj.transform(in_proj,out_proj,*station_coord)\n",
    "\n",
    "#Loop through each day in the dataframe\n",
    "for date in min_data.index:\n",
    "    \n",
    "    #Subset dataframe to only values in day of year\n",
    "    print(f'Date: {date}')\n",
    "    temp_df = min_data[min_data.index == date]\n",
    "    temp_raster = raster.sel(time=date)\n",
    "\n",
    "    try:\n",
    "        temp_line = temp_df.loc[temp_df.index == date,:]\n",
    "\n",
    "        #Calculate footprint\n",
    "        temp_ffp = myfootprint_s.FFP_climatology(domain=[-origin_d,origin_d,-origin_d,origin_d],dx=dx,dy=dx,\n",
    "                                zm=zm_s-d, z0=h_c*.123, h=h_s, rs=None,\n",
    "                                ol=temp_line['ol'].values,sigmav=temp_line['sig_v'].values,\n",
    "                                ustar=temp_line['ustar'].values,\n",
    "                                wind_dir=temp_line['wdir_ec'].values,\n",
    "                                crop=0,fig=0,verbosity=0)\n",
    "\n",
    "        f_2d = np.array(temp_ffp['fclim_2d'])\n",
    "        x_2d = np.array(temp_ffp['x_2d']) + station_x\n",
    "        y_2d = np.array(temp_ffp['y_2d']) + station_y\n",
    "        \n",
    "        f_2d = f_2d*dx**2\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f'{t} footprint failed')\n",
    "\n",
    "        continue\n",
    "    \n",
    "    #Mask out points that are below a % threshold (defaults to 90%)\n",
    "    f_2d = ff.mask_fp_cutoff(f_2d)\n",
    "    \n",
    "    #Create kd tree and lookup dataframe from the imagery\n",
    "    kd, combine_xy = ff.footprint_ckdtree(temp_raster)\n",
    "        \n",
    "    weighted_ef = ff.weight_raster(x_2d, y_2d, f_2d, combine_xy, kd)\n",
    "    min_data.loc[date,'ef_footprint_raw'] = weighted_ef\n",
    "    min_data.loc[date,'ef_footprint'] = weighted_ef/.9\n",
    "    print(weighted_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_data['ef_station'] = min_data['le_closed'] / (min_data['rn_avg'] - min_data['gflux_avg'])\n",
    "min_data.to_csv(os.path.join(tri_dir, raster_str, f'{raster_str}_output_run2_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
